{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of ai_course_house_prices.ipynb","provenance":[{"file_id":"https://github.com/NordAxon/AI-For-Leaders/blob/master/ai_course_house_prices_with_solutions.ipynb","timestamp":1578398303802},{"file_id":"https://github.com/NordAxon/AI-For-Leaders/blob/master/ai_course_house_prices_with_solutions.ipynb","timestamp":1571121442590},{"file_id":"https://github.com/NordAxon/AI-For-Leaders/blob/master/ai_course_house_prices_with_solutions.ipynb","timestamp":1547407549391},{"file_id":"https://github.com/NordAxon/AI-For-Leaders/blob/master/ai_course_house_prices_with_solutions.ipynb","timestamp":1547293757001},{"file_id":"https://github.com/NordAxon/AI-For-Leaders/blob/master/ai_course_house_prices_with_solutions.ipynb","timestamp":1546847630273}],"collapsed_sections":["unUCaszMfGHd"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"unUCaszMfGHd"},"source":["#BASIC INFORMATION (ReadMe)\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4pqCFgd59HDe"},"source":["**1.  About Jupyter Notebook and Google Colab**\n","- Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning etc.\n","- Google Colaboratory is a free Jupyter notebook environment that requires no setup and runs entirely in the cloud. \n","\n","**2.   About this lab**\n","\n","- In this lab we will explore and use Melbourne housepricing dataset.  Each row in the dataset is a housing sale and columns are the features of the sold house/appartment.\n","\n","\n","- The goal is to predict the price of new sales. We will build two supervised models: regression models and artificial neural network. ML pipeline outlined in the theory part of the course will be followed. \n","\n","\n","**3.  How to save own version of the Jupyter notebook**\n","\n","- Go to File and choose \"Save a copy in Drive\". This will save your code notebook on your Google Drive.\n","\n","**4.   How to run/execute cell of code**\n","\n","- Alt 1: Ctrl+Enter tab through the code.\n","- Alt 2: Shift+Enter tab through the code.\n","- Alt 3:  Mark the cell,  press \"Run\" button on the left side of the cell.\n","\n","\n","**5.  More info about dataset**\n"," - Data source: https://www.kaggle.com/anthonypino/melbourne-housing-market\n","\n","\n"," - Columns/fields in the dataset:\n","1. Suburb: Suburb\n","2. Address: Address\n","3. Rooms: Number of rooms\n","4. Price: Price in Australian dollars, AUD\n","5. Method: S - property sold; SP - property sold prior; PI - property passed in; PN - sold prior not disclosed; SN - sold not disclosed; NB - no bid; VB - vendor bid; W - withdrawn prior to auction; SA - sold after auction; SS - sold after auction price not disclosed. N/A - price or highest bid not available.\n","6. Type: br - bedroom(s); h - house,cottage,villa, semi,terrace; u - unit, duplex; t - townhouse; dev site - development site; o res - other residential.\n","7. SellerG: Real Estate Agent\n","8. Date: Date sold\n","9. Distance: Distance from CBD in Kilometres \n","10. Regionname: General Region (West, North West, North, North east ...etc)\n","11. Propertycount: Number of properties that exist in the suburb\n","12. Bedroom2 : Scraped # of Bedrooms (from different source)\n","13. Bathroom: Number of Bathrooms\n","14. Car: Number of carspots\n","15. Landsize: Land Size in Metres\n","16. BuildingArea: Building Size in Metres\n","17. YearBuilt: Year the house was built\n","18. CouncilArea: Governing council for the area\n","19. Lattitude: Self explanitory\n","20. Longtitude: Self explanitory\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GxQPuTJZvTgJ"},"source":["#1) CLONE ENVIRONMENT & IMPORT LIBRARIES"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"znqzyheRvdbX"},"source":["##1.1. Get all the files\n","- Run the below code cell if the notebook is opened in Google Collab. It will clone the GitHub repository to get all necessary files."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LsbGyPMrfGHk","colab":{}},"source":["!git clone https://github.com/NordAxon/AI-For-Leaders.git"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9eWT63iMfGHs"},"source":["## 1.2 Import libraries\n","There are a great deal of python libraries that are available for Machine Learning. Read about some of the most used libraries here: https://hackernoon.com/top-10-libraries-in-python-to-implement-machine-learning-12602cf5dc61\n","\n","For the libraries used in this lab, please see the following links:\n","\n","\n","> - Pandas: https://pandas.pydata.org/pandas-docs/stable/index.html <br>\n","> - Scikit-learn: https://scikit-learn.org/stable/ <br>\n","> - Keras: https://keras.io/\n","> - Seaborn: https://seaborn.pydata.org\n","\n","Let's import all the libraries we need to run the code and perform the analysis. Run the code cell below."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"I_M2OQmuv4qb","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from sklearn import linear_model\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.datasets import make_regression\n","from sklearn.metrics import mean_absolute_error\n","\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.wrappers.scikit_learn import KerasRegressor\n","\n","import seaborn as sns\n","\n","pd.set_option('display.max_columns', 100)\n","%load_ext autoreload\n","%autoreload 2\n","\n","np.random.seed(1)\n","\n","#Functions for printing evaluation results\n","def print_results_linreg (mean_absolute_error_simple_formated, mean_baseline_error_formated):\n","    print(\"\\n******************* ALL RESULTS IN THIS EXECUTION ROUND *********************************************\\n\")\n","    print('* Mean Absolute Error with Simple Linear Regression = ' + mean_absolute_error_simple_formated)\n","    print('* Mean Absolut Error for Baseline Model = ' + mean_baseline_error_formated)\n","\n","    if mean_absolute_error_simple_formated < mean_baseline_error_formated:\n","        print ('\\nMean Absolute Error with Simple Linear Regression is smaller then Mean Absolute Error as Baseline Model. Good!')\n","    print (\"\\n*****************************************************************************************************\")\n","\n","def print_results_multidim (mean_absolute_error_multidim_formated, mean_absolute_error_simple_formated):\n","    print(\"\\n***************************** EVALUATION RESULTS IN THIS EXECUTION ROUND **************************************** \\n\")\n","    print('* MAE with Multi-Dimensional Linear Regression = ' + mean_absolute_error_multidim_formated)\n","    print('* MAE with Simple Linear Regression = ' + mean_absolute_error_simple_formated)\n","\n","    if mean_absolute_error_multidim_formated < mean_absolute_error_simple_formated:\n","        print ('\\n Mean Absolute Error with Multi-Dimensional Linear Regression is smaller than Simple Linear Regression\". \\n Good, our new multivariable regression model is better!')\n","    print (\"\\n*****************************************************************************************************************\")\n","\n","def print_results_nn (mean_nn_error_formated): \n","    print (\"\\n ***************** EVALUATION RESULTS IN THIS EXECUTION ROUND *********************\\n\")\n","    print (\"* MAE with Simple Linear Regression = \"+ mean_absolute_error_simple_formated)\n","    print (\"* MAE with MultiDimensional Linear Regression = \"+ mean_absolute_error_multidim_formated)\n","    print (\"* MAE with this NN execution = \"+ mean_nn_error_formated)\n","    print (\"\\n***********************************************************************************\")\n","\n","def print_results_rf(mean_rf_error_formated):\n","    print (\"\\n ***************** EVALUATION RESULTS IN THIS EXECUTION ROUND *********************\\n\")\n","    print (\"* MAE with Simple Linear Regression = \"+ mean_absolute_error_simple_formated)\n","    print (\"* MAE with MultiDimensional Linear Regression = \"+ mean_absolute_error_multidim_formated)\n","    print (\"* MAE with this NN execution = \"+ mean_nn_error_formated)\n","    print (\"* MAE with Random Forest execution = \"+ mean_rf_error_formated)\n","    print (\" \\n Random Forest rules on this dataset :) \")\n","    print (\"\\n***********************************************************************************\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"55zikYrPw_V0"},"source":["# 2) IMPORT RAW DATA"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ko97OSflfGHy","colab":{}},"source":["#housing_df_original = pd.read_csv('AI-For-Leaders/data/melbourne-housing-market/Melbourne_housing.csv')\n","housing_df_original = pd.read_csv('AI-For-Leaders/data/melbourne-housing-market/Melbourne_housing_shuffled.csv')\n","housing_df_original"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OKO3iwwefGH1","colab":{}},"source":["# Size of the dataset (X, Y)\n","print ('Nr of rows and Nr of columns: ' + str(housing_df_original.shape))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UoOdOB70fGH4"},"source":["# 3) EXPLORE & PRE-PROCESSING DATA"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4ANxdz-a_4YI"},"source":["##  3.1. Fill in empty/missing data\n","\n","In some of the columns we have NaN (Not a Number) values, wich means that there is missing data.\n","\n","Many ML algorithms need data in all rows and columns, so the NaNs have to be replaced with something meaningful. E.g. where \"Landsize\" is marked \"NaN\", this will be replaced with 0 to properly indicate that there is no land connected to the property. \n","\n","\n","\n"," \n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YDW8L9n6H4td"},"source":["Let's first have a look at how many NaN values are present in each column. \n","- Run the code cell below"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7QzV0cPDfGH7","colab":{}},"source":["print('Number of NaNs for every variable: ')\n","print(pd.isnull(housing_df_original).sum())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JtbVw15XfGH-"},"source":["- Lets clean and fill/replace missing values <br>\n","\n",">1.   Remove rows where there is no price\n",">2.   Fill NaN values in columns BuildingArea, Rooms, Landsize, Car, Bathroom, Bedroom2 with 0\n",">3.   For column YearBuilt, fill NaN values with the median value of that column, since that houses in Melbourne being built at year 0 seems unlikely\n","\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"q6LjBN5zfGH_","colab":{}},"source":["housing_df_no_nan = housing_df_original.copy()\n","\n","# Remove all rows with no price data\n","housing_df_no_nan = housing_df_no_nan[pd.notnull(housing_df_no_nan['Price'])]\n","\n","# Replace NaN values with 0 values in columns BuildingArea, Rooms, Landsize, Car, Bathroom, Bedroom2 \n","housing_df_no_nan['BuildingArea'].fillna(0.0, inplace=True)\n","housing_df_no_nan['Rooms'].fillna(0.0, inplace=True)\n","housing_df_no_nan['Landsize'].fillna(0.0, inplace=True)\n","housing_df_no_nan['Car'].fillna(0.0, inplace=True)\n","housing_df_no_nan['Bathroom'].fillna(0.0, inplace=True)\n","housing_df_no_nan['Bedroom2'].fillna(0.0, inplace=True)\n","\n","# Replace NaN values in YearBuilt column with median value of that column\n","housing_df_no_nan['YearBuilt'].fillna(housing_df_no_nan['YearBuilt'].median(), inplace=True)\n","\n","print('Number of NaNs for every variable:')\n","print(pd.isnull(housing_df_no_nan).sum())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PHbIauHMfGID"},"source":["##**3.2. Plot variable correlations and histograms**\n","\n","Let's have a look at how different variables relate to each other and how the data is distributed. \n","\n","The goal is to get insight in our dataset, understand how different columns relate to each other and look for outliers.\n","\n","Let's pick some columns (variables) we think might be good predictors of price and plot those against each other as *scatter plots* and *histograms*. In a real project we would have plotted all variables in many different ways, but let's restrict the time spent on this by only picking six variables.\n","\n","* Run the code below\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mHq6CgV6fGIF","colab":{}},"source":["plot_str_arr = ['BuildingArea', 'Rooms', 'Landsize', 'Car', 'Bathroom', 'Price']\n","f, axarr = plt.subplots(2, len(plot_str_arr), figsize=(22,7))\n","\n","i = 0\n","for plt_str in plot_str_arr:\n","    sns.regplot(x=plt_str, y=\"Price\", data=housing_df_no_nan, ax=axarr[0,i])\n","    housing_df_no_nan[plt_str].hist(ax=axarr[1,i])\n","    i += 1\n","axarr[1,5].set_ylim([0,7000])\n","f.canvas.set_window_title('Scatter Plots and Histograms')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bB2QMBvjfGIJ"},"source":["## 3.3. Remove outliers\n","\n","Outliers are data points located far away from the main mass of the data. These come with a risk of skewing the models and we would therefore like to remove them. \n","\n","In the plots above it seems like we have outliers in some of the columns. We will take a deeper look at some variables which seem to contain outliers. \n","\n","- Run the cell below to see a plot of *BuildingArea vs Price* where it is clear that we have some data points which are far away from the others"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Z93dzDhSfGIJ","colab":{}},"source":["housing_df_no_nan.plot.scatter('BuildingArea', 'Price', title='Price [AUD] vs. Building Area [m^2]')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wH5Dfrv3fGIN"},"source":["1)   Set clip-offs:\n","\n","\n","\n","*   Building area = 500 m^2 (all data points larger than 500 will be set to 500)\n","*   Price= 4 000 000 AUD\n","\n","2)  Plot again! "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vEHINI-YfGIO","colab":{}},"source":["housing_clipped = housing_df_no_nan.copy()\n","housing_clipped['BuildingArea'] = housing_clipped['BuildingArea'].clip(0, 500)\n","housing_clipped['Price'] = housing_clipped['Price'].clip(0, 4e6)\n","housing_clipped.plot.scatter('BuildingArea', 'Price', title='Price [AUD] vs. Building Area [m^2]')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YPBN0qR9fGIR"},"source":["### ASSIGNMENT 1:\n","\n","- Plot \"Landsize\" (unit=m^2) vs \"Price\" in the empty code cell below. \n","\n","Does it look like there are some outliers? If so, what could be a resonable cut-off level? <br>\n","\n","***Hint:*** Have a look above at the statistical printouts for Landsize.\n","- Clip the data set to remove Landsize outliers, i.e replace the value of variable landsize_max with a resonable number. Plot again!\n","- Important, name your variable *housing_clipped_2* "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XgY2E-2JfGIS","colab":{}},"source":["# ENTER CODE HERE\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-JPpakbEfGIZ"},"source":["## 3.4 Plot histograms for indicative columns\n","- Lets have a look more closely at the variables we think could be interesting by plotting seperate and larger histograms."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7sNLlcJufGIa","colab":{}},"source":["housing_clipped_2['BuildingArea'].hist(bins=40, figsize=(10,7))\n","plt.title('Histogram of Building Areas');"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ed036kDmfGIc"},"source":["### ASSIGNMENT 2:\n","\n","- Create a histogram of the variable Price in the empty code cell below\n","\n","***Hint:** use the same number of bins and figure size as above"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rQsuhsmpfGIe","colab":{}},"source":["# CODE HERE\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"OEcuxYO6fGIi"},"source":["## 3.5 Price for different regions\n","We are hypothesising that the property location will have an impact on the price. \n","- Run the code below to plot to get a feel for how the price behaves in different locations"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fS01K03AfGIk","colab":{}},"source":["plt.figure(figsize=(10,7))\n","housing_clipped_2.groupby('Regionname')['Price'].mean().plot.bar();"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jvYrjgnNfGIp"},"source":["### ASSIGNMENT 3: \n","- Plot the average (mean) price for the each different CouncilArea, to see how they compare to one another"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"w2C7FLWqfGIq","colab":{}},"source":["# CODE HERE\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"IPLyTEaxfGIu"},"source":["# 4) BUILD/TRAIN MODEL: SIMPLE LINEAR REGRESSION\n","\n","We are getting a feeling for what the data looks like, so now we might try a first model for predicting the price on the properties for sale. \n","\n","The simple linear regression, with one predictor variable (X) and one output variable (Y), is a very commonly used model. \n","\n","- We pick BuildingArea as a predictor to begin with, since there seem to be a correlation between BuildingArea and Price according to our exploration through the plots. \n","\n","- The goal is to find all of the weights, $w_i$, in the following linear regression model. \n","\n","\n","> $y = w_0 + w_1x_1$\n","\n","\n","***Need a review?*** For more information about supervised learning and regression, look up section 3 in the course material, slide 24, for the simple linear regression.\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7wmuh5WnyGMU"},"source":["## 4.1 Split dataset, pick algorithm, train model\n","\n","- Run the code below to set up the variables, split the data set and train the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uFoS970OfGIv","colab":{}},"source":["# Set up input (x) and output (y) variables\n","x = housing_clipped_2[['BuildingArea']]\n","y = housing_clipped_2['Price']\n","\n","# Split into test and train data\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, shuffle=False)\n","\n","# Set up and train simple linear regression model\n","regr = linear_model.LinearRegression()\n","regr.fit(x_train, y_train)\n","\n","# Perform predictions on testset\n","y_pred_simple = regr.predict(x_test)\n","\n","\n","### Plot results ###\n","\n","# Prepare plotting figure and axes\n","plt.figure(figsize=(15,10));\n","plt.title('Simple Linear Regression Model');\n","plt.xlabel('BuildingArea [m^2]', fontsize=10)\n","plt.ylabel('Price [AUD]', fontsize=10)\n","\n","# Plot training data in green color\n","plt.scatter(x_train.values, y_train.values, color='green', alpha=0.2)\n","# Plot test data in red color\n","plt.scatter(x_test.values, y_test.values, color='red', alpha=0.2)\n","\n","# Plot the simple regression line based on test data in blue color\n","plt.plot(x_test, y_pred_simple, 'b')\n","\n","print (regr.coef_)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TnYXFGcMfGIz"},"source":["## 4.2 Model evaluation\n","The error value will be compared to a baseline error, which is the error compared to if the prediction is just the mean of previous house values. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"g8RVKZ_LfGIz","colab":{}},"source":["# Evaluate Results\n","\n","mean_absolute_error_simple = int((y_pred_simple - y_test).abs().mean())\n","mean_absolute_error_simple_formated = str('{:,}'.format(mean_absolute_error_simple).replace(',',' '))\n","mean_baseline_error = int((y_train.mean() - y_test).abs().mean())\n","mean_baseline_error_formated = str('{:,}'.format(mean_baseline_error).replace(',',' '))\n","\n","# Printing results of evaluation\n","print_results_linreg(mean_absolute_error_simple_formated, mean_baseline_error_formated)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BlVURIwtfGI3"},"source":["# 5) BUILD/TRAIN MODEL: MULTI-DIMENSIONAL LINEAR REGRESSION\n","\n","In order to increase the predictive power - i.e. to get a more accurate model - more information can be added to the model. \n","\n","One way of doing that is by adding more input variables to the model. Variables that could be tried are BuildingArea, Rooms, LandSize, Car. \n","\n","**Need a review?** The formula for the multi-dimensional linear regression is:\n","\n","> $y = w_0 + w_1x_1 + w_2x_2 + \\dots$\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7eE0As8E0NoT"},"source":["## 5.1 Split dataset, pick algorithm, train model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"v1q5lPyTfGI6","colab":{}},"source":["# Select fields/features for the model\n","features_list = ['BuildingArea', 'Rooms', 'Car', 'Landsize']\n","x = housing_clipped_2[features_list]\n","y = housing_clipped_2['Price']\n","\n","# Split into test and train data\n","x_train_multidim, x_test_multidim, y_train_multidim, y_test_multidim = train_test_split(x, y, test_size=0.2, shuffle=False)\n","\n","# Set up and train regression model\n","regr_multidim = linear_model.LinearRegression()\n","regr_multidim.fit(x_train_multidim, y_train_multidim)\n","\n","# Perform predictions\n","y_pred_multidim = regr_multidim.predict(x_test_multidim)\n","\n","\n","######### Plot results ##########\n","\n","# Prepare plotting figure and axes\n","plt.figure(figsize=(15,10));\n","plt.title('Multidimensional Linear Regression Model');\n","plt.xlabel('BuildingArea [m^2]', fontsize=10)\n","plt.ylabel('Price [AUD]', fontsize=10)\n","\n","# Plot training data in green color\n","plt.scatter(x_train_multidim['BuildingArea'].values, y_train_multidim.values, color='green', alpha=0.2)\n","# Plot test data in red color\n","plt.scatter(x_test_multidim['BuildingArea'].values, y_test_multidim.values, color='red', alpha=0.2)\n","\n","# Plot the multidim regression line based on test data in black color\n","plt.plot(x_test_multidim['BuildingArea'], y_pred_multidim, 'k.')\n","#plt.plot(x_test_multidim['BuildingArea'], y_pred_simple, 'b')\n","\n","\n","# Print regression coefficients, w\n","print('* Regression coefficients:')\n","i=0\n","print('Nr of features used = ' + str(len(features_list)))\n","while i<len(features_list):\n","    print(features_list[i] + ' = ' + str(regr_multidim.coef_[i]))\n","    i+=1\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wqXs0nUhfGI-"},"source":["## 5.2 Model evaluation"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"N9aYkhUxfGI_","colab":{}},"source":["# Evaluate Results\n","mean_absolute_error_multidim = int((y_pred_multidim - y_test_multidim).abs().mean())\n","mean_absolute_error_multidim_formated = str('{:,}'.format(mean_absolute_error_multidim).replace(',',' '))\n","\n","# Printing results of evaluation\n","print_results_multidim (mean_absolute_error_multidim_formated, mean_absolute_error_simple_formated)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cbnGfn6ufGJB"},"source":["## ASSIGNMENT 4:\n","- Test your multidimensional model by adding some more fields/features, look up in the dataset columns list (20 available)\n",">**Q 4.1:** Write down the results and compare!\n","\n","**Hint**: Modify the second line of code in section 5.1. Add/remove features in features_input_list. Retrain the model and evaluate!\n","\n","**Answers**: Provide them in the separate \"Solutions and Answering sheet\" document. \n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FMi7dYXRfGJC"},"source":["# 6) BUILD/TRAIN MODEL: ARTIFICAL NEURAL NETWORK\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pthSByV35oL7"},"source":["## 6.1 Split dataset, pick algorithm, train & evaluate model\n","\n","The code in the following cell transforms data, builds a neural network and evaluates results of predictions from the neural net.\n","\n","Some good reading about the different steps using the Keras library:\n","https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n","\n","***Need a review?*** For more information about ANN, look up section 4 in the course material."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mIZj-9n2fGJI","colab":{}},"source":["def run_neural_network(x, y, n_epochs=10, layer_list=[100,20], dropout_bool=False):\n","    global mean_nn_error_formated\n","\n","    # Split the dataset in training and test sets, skipping the validation set.\n","    x_train_nn, x_test_nn, y_train_nn, y_test_nn = train_test_split(x, y, train_size=0.8, test_size=0.2, shuffle=False)\n","    \n","    # Scale the data\n","    #scaler = MinMaxScaler()\n","    scaler = StandardScaler()\n","\n","    x_train_nn = scaler.fit_transform(x_train_nn)\n","    x_test_nn = scaler.transform(x_test_nn)\n","    y_train_nn = scaler.fit_transform(y_train_nn.values.reshape(len(y_train_nn),1))\n","    y_test_nn= scaler.transform(y_test_nn.values.reshape(len(y_test_nn),1))\n","   \n","    # Define the NN structure (with Keras): 3 layers with (100,20,1) neurons, train.shape[1] input variables\n","    model = Sequential()\n","    model.add(Dense(layer_list[0], input_dim=x_train_nn.shape[1], activation='relu'))\n","    for layer_size in layer_list[1:]:\n","        if dropout_bool:\n","            model.add(Dropout(0.3))\n","        model.add(Dense(layer_size, activation='relu'))\n","    model.add(Dense(1, activation='linear'))\n","    \n","    # Plot model summary\n","    # print(model.summary())\n","    \n","    # Compile model \n","    model.compile(loss='mse', optimizer='adam', metrics=['mean_squared_error', 'mean_absolute_error'])\n","\n","    # Train the model\n","    history = model.fit(x_train_nn, y_train_nn, epochs=n_epochs, verbose=0, validation_data=(x_test_nn, y_test_nn))\n","\n","    # Make a prediction\n","    y_pred_nn = model.predict(x_test_nn)[:,0]\n","    \n","    # Show the inputs and predicted outputs\n","    y_pred_nn = scaler.inverse_transform(y_pred_nn.reshape(len(y_pred_nn),1))\n","    y_test_nn = scaler.inverse_transform(y_test_nn)\n","\n","    # Evaluate results\n","    mean_nn_error = int((pd.Series(y_pred_nn[:,0]) - y_test_nn[:,0]).abs().mean())\n","    mean_nn_error_formated = str('{:,}'.format(mean_nn_error).replace(',',' '))\n","    \n","    # Print evaluations\n","    print_results_nn(mean_nn_error_formated)\n","\n","    # Plot error over training time\n","    plt.figure(figsize=(10,7))\n","    plt.plot(history.history['mean_squared_error'], label='Train')\n","    plt.plot(history.history['val_mean_squared_error'], label='Validation')\n","    plt.title('Model Loss')\n","    plt.ylabel('Mean Squared Error')\n","    plt.xlabel('Epoch')\n","    #plt.legend(['Test', 'Train'], loc='upper left')\n","    plt.legend()\n","    plt.show()\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_HacFgP8D0sS","colab_type":"text"},"source":["## 6.2 Run ANN model:\n","Run the model a couple of times to see that the results may differ between runs. The reason for this is that weights are initialized randomly and that the training algorithm contains some random operations. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"A4iIv_dbt48y","colab":{}},"source":["# Select fields/features for the model\n","features_list = ['BuildingArea', 'Rooms', 'Car', 'Landsize', 'Bathroom']\n","x = housing_clipped_2[features_list]\n","y = housing_clipped_2['Price']\n","\n","# Train/run neural network\n","run_neural_network(x, y, 20, [20, 10])\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"LaJnbTnufGJM"},"source":["### ASSIGNMENT 5:\n","- Try running the model with different number of training epochs. \n",">**Q 5.1:** What happens with the loss for a higher amount of training epochs?\n","\n","**Hint:** Modify last line of code under section 6.2\n","\n","**Answers:** Provide them in the separate \"Solutions and Answering sheet\" document. \n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zDM8gYfIfGJP"},"source":["## 6.3 Improving ANN model - Adding more features\n","\n","- Let's look at the data to see what we can do with it to create columns which are more easily readable for a ML algorithm and how we can get more insights from the data we have.\n","- Lets try and make the predictive model as good as possible by adding more features such as location and age of property. "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"yXWtQLXBfGJV"},"source":["### 6.3.1 Add feature: House age\n","Using the year of construction for a house straight away as a feature is not a good idea, since most values will be around the 2000s. \n","\n","A small difference in the absolute value of a feature might lead to a big difference in the actual house value; e.g. a house built in 2017 is probably a lot more valuable than a house built in 2007. To emphasize the differences in our dataset, we will create the age of the building from the variable *YearBuilt*. \n","\n","We also log-transform the age to make it a bit more convenient for ML algorithms. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0VpLD8eNfGJW","colab":{}},"source":["# Create house_ages feature\n","year_built = housing_clipped_2['YearBuilt'].clip(0,2020)\n","house_ages = pd.Series(np.log((1 + (2020. - year_built))))\n","house_ages = house_ages.fillna(house_ages.mean())\n","house_ages.name = 'Age'\n","plt.figure()\n","house_ages.hist()\n","plt.title('Distribution After Logarithm')\n","house_ages_df = pd.DataFrame(house_ages)\n","features_w_age = pd.concat([housing_clipped_2, house_ages_df], axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2edkqykLE7xs","colab_type":"text"},"source":["*  Run the model with the *house_ages* feature added.\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Eprq5-apfGJe","colab":{}},"source":["# Select fields/features for the model\n","new_feature_list = ['BuildingArea', 'Rooms',  'Car', 'Landsize'] + ['Age'] # + list(one_hot_region.columns)\n","\n","# Train/execute neural network\n","run_neural_network(features_w_age[new_feature_list], features_w_age['Price'], n_epochs=20, layer_list=[20,10])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nYFsez2pfGJT"},"source":["### 6.3.2 Add feature: Regionname \n","*   Add Regionname as a feature by transforming it to one-hot encoding\n","\n","*   Run the model with feature Regionname added\n","\n","**Need a review?** For more information about feature engineering look up section 5.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1MHW2RhCfGJQ","scrolled":true,"colab":{}},"source":["# Create region name feature with One-Hot encoding\n","one_hot_region = pd.get_dummies(housing_clipped_2.Regionname, prefix='Regionname')\n","region_feature = pd.concat([housing_clipped_2, one_hot_region], axis=1)\n","\n","# Select fields/features for the model\n","new_feature_list = ['BuildingArea', 'Rooms', 'Car', 'Landsize'] + list(one_hot_region.columns)\n","x_new_features = region_feature[new_feature_list]\n","y_new_features = region_feature['Price']\n","\n","# Train/execute neural network\n","run_neural_network(x_new_features, y_new_features, layer_list=[20,10])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4DloLeYNg_kO","colab_type":"text"},"source":["\n","### ASSIGNMENT 6:\n","* Try different sizes of the neural network. \n","* Try out the below network configurations and observe the MAE (Mean Absolute Error) for test and train data.The lists below are denoted such that the 1st entry represents the number of neurons in the 1st layer, 2nd entry in the 2nd layer and so on.\n","\n",">1.   Configuration 1: [2, 1]\n",">2.   Configuration 2: [20, 10]  (increasing the number or neurons)\n",">3.   Configuration 3: [1000, 100] (increasing the number or neurons even more)\n",">4.   Configuration 4: [5, 5, 5, 2] (more layers, the term deep learning originates from using many layers)\n",">5.   Configuration 5: Test your own configuration if you want to.\n","\n","\n","**Hint:** Modify 11th line of code under section 6.3.2\n","\n","\n","> **Q 6.1:** What are the results when adding more layers? <br>\n","**Q 6.2:** What are the results when adding more neurons? <br>\n","**Q 6.3:** When is there a difference between the train and test data in Mean Squared Error?  <br> \n","\n","**Answers:** Provide them in the separate \"Solutions and Answering sheet\" document. "]},{"cell_type":"markdown","metadata":{"id":"G4ULQ-y7m4JE","colab_type":"text"},"source":["# EXTRA & DISCUSSION EXERCISES"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"EBj5rJHO2FM5"},"source":["### ASSIGNMENT 7 (EXTRA): \n","Trying adding more features  by adjusting the code above.\n","\n","> **Q 7.1:** Which columns/features could be useful for providing more predictive power?  <br> \n","\n","**Answers:** Provide them in the separate \"Solutions and Answering sheet\" document. "]},{"cell_type":"code","metadata":{"id":"LYahATXo54zs","colab_type":"code","colab":{}},"source":["# ENTER CODE HERE\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3TibbFuctI4H","colab_type":"text"},"source":["## ASSIGNMENT 8 (EXTRA):\n","\n","ML flow step 5, section 5 in the course material, emphasizes the importance of trying different algorithms when looking for the best performing model. \n","\n","In the code cells below create, build and train a Random Forest model. Compare the MAE results from those models with model results from above. \n","\n","Please refer to the Scikit-learn documentation:\n","\n","\n","> **Random Forest** <br>\n","https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html <br>\n","https://stackabuse.com/random-forest-algorithm-with-python-and-scikit-learn/\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"kFMBwXAd0soU","colab_type":"code","colab":{}},"source":["# SOLUTION:\n","\n","from sklearn.ensemble import RandomForestRegressor\n","regr = RandomForestRegressor(max_depth=None, random_state=0, n_estimators=200)\n","\n","x_train_rf, x_test_rf, y_train_rf, y_test_rf = train_test_split(x_new_features, y_new_features, train_size=0.8, test_size=0.2, shuffle=False)\n","regr.fit(x_train_rf, y_train_rf)\n","y_pred_rf = regr.predict(x_test_rf)\n","\n"," # Evaluate results\n","mean_rf_error = int(round (mean_absolute_error(y_test_rf, y_pred_rf),0))\n","mean_rf_error_formated = str('{:,}'.format(mean_rf_error).replace(',',' '))\n","\n","# Print results of the evaluation\n","print_results_rf(mean_rf_error_formated)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8BEJR_BdfGJO"},"source":["## ASSIGNMENT 9 (DISCUSSION QUESTIONS):\n","\n","> **Q 9.1:** What were the two lowest MAE (Mean Absolute Error) values you got and from which models? Why do you think it was these models that performed the best? <br>\n","**Q 9.2:** Why does a well-tuned neural network perform better than a linear regression model in this case?  <br>\n","**Q 9.3:** What could be done to improve model performance?  <br>  \n","\n","**Answers:** Provide them in the separate \"Solutions and Answering sheet\" document. \n","\n","\n"]}]}